{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt: \n",
    "```\n",
    "Oi, pode implementar o algoritmo KNN, na linguagem python, porém sem usar bibliotecas com o algoritmo já pronto, apenas bibliotecas vetoriais como o numpy.\n",
    "```    \n",
    "Resposta:\n",
    "```python\n",
    "Claro! Aqui está uma implementação simples do algoritmo K-Nearest Neighbors (KNN) em Python utilizando apenas bibliotecas básicas como o NumPy para manipulação de arrays:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Armazena os dados de treino.\"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Prediz os rótulos de dados de teste.\"\"\"\n",
    "        predictions = [self._predict(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        \"\"\"Prediz o rótulo para um único ponto de dados.\"\"\"\n",
    "        # Calcula as distâncias euclidianas de x para todos os pontos de treino\n",
    "        distances = [np.linalg.norm(x - x_train) for x_train in self.X_train]\n",
    "        \n",
    "        # Pega os índices das k menores distâncias\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # Pega os rótulos correspondentes a esses k pontos mais próximos\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        \n",
    "        # Retorna o rótulo mais comum (maioria)\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "# Exemplo de uso:\n",
    "if __name__ == \"__main__\":\n",
    "    # Dados de treino (X_train -> características, y_train -> rótulos)\n",
    "    X_train = np.array([[1, 2], [2, 3], [3, 4], [6, 5], [7, 7], [8, 9]])\n",
    "    y_train = np.array([0, 0, 0, 1, 1, 1])\n",
    "    \n",
    "    # Dados de teste\n",
    "    X_test = np.array([[5, 5], [0, 1]])\n",
    "\n",
    "    # Instanciando o classificador KNN com k=3\n",
    "    knn = KNN(k=3)\n",
    "    \n",
    "    # Treinando o modelo\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Fazendo previsões\n",
    "    predictions = knn.predict(X_test)\n",
    "    print(\"Predições:\", predictions)\n",
    "Explicação:\n",
    "KNN é um algoritmo baseado em instância que armazena todos os dados de treino e, ao prever um novo ponto de dados, ele:\n",
    "Calcula a distância (nesse caso, distância euclidiana) do ponto de teste para todos os pontos de treino.\n",
    "Seleciona os k vizinhos mais próximos (menores distâncias).\n",
    "Faz uma votação majoritária dos rótulos desses vizinhos para determinar a classe de saída.\n",
    "Exemplo de saída:\n",
    "Se executarmos o exemplo acima, as predições podem ser algo como:\n",
    "\n",
    "less\n",
    "Copy code\n",
    "Predições: [1 0]\n",
    "Esse algoritmo é bastante simples e pode ser ajustado para incluir variações, como diferentes métricas de distância ou técnicas de ponderação para os vizinhos.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = [self._predict(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [np.linalg.norm(x - x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 96.67%\n",
      "Precisão: 96.67%\n",
      "Recall: 96.97%\n",
      "F1-Score: 96.66%\n",
      "Matriz de Confusão:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  1 10]]\n"
     ]
    }
   ],
   "source": [
    "from KNN import KNN\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iris = datasets.load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    knn = KNN(k=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    predictions = knn.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average='macro')\n",
    "    recall = recall_score(y_test, predictions, average='macro')\n",
    "    f1 = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "    print(f\"Acurácia: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precisão: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1 * 100:.2f}%\")\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
